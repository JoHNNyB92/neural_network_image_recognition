{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras import optimizers\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten, Dense, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import time;\n",
    "import imp\n",
    "import numpy as np \n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import cifar10\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import ParameterGrid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "The functions below are used to load,pre-process,show information and plot model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def load_cifar():\n",
    "    (train_features, train_labels), (test_features, test_labels) = cifar10.load_data()\n",
    "    num_train, img_channels, img_rows, img_cols =  train_features.shape\n",
    "    num_test, _, _, _ =  test_features.shape\n",
    "    num_classes = len(np.unique(train_labels))\n",
    "    return train_features,train_labels,test_features,test_labels   \n",
    "\n",
    "def normalize(x):\n",
    "    min_val = np.min(x)\n",
    "    max_val = np.max(x)\n",
    "    x = (x-min_val) / (float)(max_val-min_val)\n",
    "    return x   \n",
    "    \n",
    "def information(labels,names):\n",
    "    c=Counter(labels)\n",
    "    for nm in names:\n",
    "        print (\"Label:\",nm,\"Counter:\",c[nm]) \n",
    "        \n",
    "        \n",
    "def accuracy(test_x, test_y, model):\n",
    "    result = model.predict(test_x)\n",
    "    print(result)\n",
    "    true_class = np.argmax(test_y, axis=1)\n",
    "    num_correct = np.sum(result == true_class) \n",
    "    accuracy = float(num_correct)/result.shape[0]\n",
    "    return (accuracy * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "Below is the core of the model. I pass 3 parameters in order to test multiple neural network architectures with a fixed number of dense layers(3) and fixed number of regularization layers (relu and batch normalization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(neurons,dropout_rate,learn_rate):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(3, 32, 32)))\n",
    "    \n",
    "    model.add(Dense(neurons,activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    # Compile model        \n",
    "    model.add(Dense((int)(neurons/2),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(Dense((int)(neurons/4),activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    \n",
    "    optimizer = Adam(lr=learn_rate)\n",
    "   \n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "Here we load the dataset and visualize some images,along with information about the number of elements per class in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape :  (50000, 3, 32, 32) (50000, 1)\n",
      "Testing data shape :  (10000, 3, 32, 32) (10000, 1)\n",
      "Label: airplane Counter: 5000\n",
      "Label: automobile Counter: 5000\n",
      "Label: bird Counter: 5000\n",
      "Label: cat Counter: 5000\n",
      "Label: deer Counter: 5000\n",
      "Label: dog Counter: 5000\n",
      "Label: frog Counter: 5000\n",
      "Label: horse Counter: 5000\n",
      "Label: ship Counter: 5000\n",
      "Label: truck Counter: 5000\n"
     ]
    }
   ],
   "source": [
    "#images should have shape (samples, channels, height, width)\n",
    "if K.backend()=='tensorflow':\n",
    "    K.set_image_dim_ordering(\"th\")\n",
    "names=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']     \n",
    "num_of_classes=10\n",
    "batch_size_m = 256\n",
    "epochs = 30\n",
    "x_train, y_train,x_test, y_test = load_cifar()\n",
    "fig = plt.figure(figsize=(8,3))\n",
    "for i in range(num_of_classes):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    idx = np.where(y_train[:]==i)[0]\n",
    "    features_idx = x_train[idx,::]\n",
    "    img_num = np.random.randint(features_idx.shape[0])\n",
    "    im = np.transpose(features_idx[img_num,::],(1,2,0))\n",
    "    ax.set_title(names[i])\n",
    "    plt.imshow(im)\n",
    "plt.show()\n",
    "print('Training data shape : ', x_train.shape, y_train.shape)\n",
    "print('Testing data shape : ', x_test.shape, y_test.shape)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_train = keras.utils.to_categorical(y_train, num_of_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_of_classes)\n",
    "\n",
    "s_labels=[names[np.argmax(i==1)] for i in y_train]\n",
    "information(s_labels,names)\n",
    "#Could be possibley done by dividing with 255(255(max number a pixel can take)-0(min number a pixel can take))\n",
    "x_train=normalize(x_train)\n",
    "x_test=normalize(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search\n",
    "Since the core architecture of the neural network is defined, I perform a grid search over the following candidate parameters and keep the neural network that achieved the highest accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROUND WITH PARAMETERS:%d 0\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 199,898\n",
      "Trainable params: 199,674\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 10s 210us/step - loss: 2.0785 - acc: 0.2594 - val_loss: 1.9842 - val_acc: 0.2819\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.8739 - acc: 0.3209 - val_loss: 1.8502 - val_acc: 0.3271\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.8241 - acc: 0.3386 - val_loss: 1.7454 - val_acc: 0.3636\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.8080 - acc: 0.3483 - val_loss: 1.7949 - val_acc: 0.3560\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.7785 - acc: 0.3610 - val_loss: 1.7920 - val_acc: 0.3480\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.7590 - acc: 0.3670 - val_loss: 1.6435 - val_acc: 0.4072\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.7435 - acc: 0.3764 - val_loss: 1.6691 - val_acc: 0.3984\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.7302 - acc: 0.3816 - val_loss: 1.6405 - val_acc: 0.4162\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.7195 - acc: 0.3852 - val_loss: 1.6506 - val_acc: 0.4034\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.7117 - acc: 0.3872 - val_loss: 1.6560 - val_acc: 0.4008\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.7015 - acc: 0.3924 - val_loss: 1.6117 - val_acc: 0.4104\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.6942 - acc: 0.3947 - val_loss: 1.6331 - val_acc: 0.4113\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.6924 - acc: 0.3913 - val_loss: 1.5972 - val_acc: 0.4219\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.6853 - acc: 0.3973 - val_loss: 1.5973 - val_acc: 0.4222\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.6776 - acc: 0.3999 - val_loss: 1.5804 - val_acc: 0.4301\n",
      "10000/10000 [==============================] - 1s 64us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 1\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_2 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 404,906\n",
      "Trainable params: 404,458\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.0221 - acc: 0.2845 - val_loss: 1.8463 - val_acc: 0.3277\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.7985 - acc: 0.3561 - val_loss: 1.6971 - val_acc: 0.3884\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.7532 - acc: 0.3715 - val_loss: 1.7954 - val_acc: 0.3321\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.7357 - acc: 0.3776 - val_loss: 1.6468 - val_acc: 0.3984\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.6956 - acc: 0.3919 - val_loss: 1.6026 - val_acc: 0.4253\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.6780 - acc: 0.4024 - val_loss: 1.5790 - val_acc: 0.4359\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.6624 - acc: 0.4061 - val_loss: 1.5903 - val_acc: 0.4259\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.6480 - acc: 0.4098 - val_loss: 1.6431 - val_acc: 0.4075\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.6410 - acc: 0.4136 - val_loss: 1.5279 - val_acc: 0.4520\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.6321 - acc: 0.4162 - val_loss: 1.5451 - val_acc: 0.4450\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.6196 - acc: 0.4225 - val_loss: 1.5700 - val_acc: 0.4371\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.6121 - acc: 0.4241 - val_loss: 1.5882 - val_acc: 0.4306\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.6106 - acc: 0.4239 - val_loss: 1.5502 - val_acc: 0.4414\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.5944 - acc: 0.4303 - val_loss: 1.5742 - val_acc: 0.4316\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.5927 - acc: 0.4302 - val_loss: 1.5619 - val_acc: 0.4342\n",
      "10000/10000 [==============================] - 1s 74us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 2\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 830,282\n",
      "Trainable params: 829,386\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 1.9599 - acc: 0.3174 - val_loss: 1.8095 - val_acc: 0.3567\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 12s 245us/step - loss: 1.7113 - acc: 0.3881 - val_loss: 1.7078 - val_acc: 0.3853\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 13s 256us/step - loss: 1.6429 - acc: 0.4126 - val_loss: 1.6126 - val_acc: 0.4182\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 13s 252us/step - loss: 1.6044 - acc: 0.4282 - val_loss: 1.5606 - val_acc: 0.4419\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 1.5859 - acc: 0.4316 - val_loss: 1.6179 - val_acc: 0.4255\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 13s 253us/step - loss: 1.5599 - acc: 0.4428 - val_loss: 1.5436 - val_acc: 0.4453\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 1.5408 - acc: 0.4503 - val_loss: 1.8160 - val_acc: 0.3628\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 13s 255us/step - loss: 1.5330 - acc: 0.4514 - val_loss: 1.5721 - val_acc: 0.4299\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 13s 252us/step - loss: 1.5128 - acc: 0.4583 - val_loss: 1.5266 - val_acc: 0.4553\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 13s 252us/step - loss: 1.4978 - acc: 0.4650 - val_loss: 1.6055 - val_acc: 0.4270\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 13s 250us/step - loss: 1.4966 - acc: 0.4647 - val_loss: 1.4856 - val_acc: 0.4788\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 13s 254us/step - loss: 1.4911 - acc: 0.4674 - val_loss: 1.5791 - val_acc: 0.4343\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.4844 - acc: 0.4674 - val_loss: 1.4538 - val_acc: 0.4753\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 1.4685 - acc: 0.4749 - val_loss: 1.5073 - val_acc: 0.4547\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 1.4613 - acc: 0.4787 - val_loss: 1.4600 - val_acc: 0.4751\n",
      "10000/10000 [==============================] - 1s 95us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 3\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 199,898\n",
      "Trainable params: 199,674\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.9832 - acc: 0.2759 - val_loss: 1.8885 - val_acc: 0.2888\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.8505 - acc: 0.3297 - val_loss: 1.9798 - val_acc: 0.2917\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.8157 - acc: 0.3467 - val_loss: 1.7814 - val_acc: 0.3458\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.7857 - acc: 0.3586 - val_loss: 2.0648 - val_acc: 0.2800\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.7591 - acc: 0.3699 - val_loss: 1.7363 - val_acc: 0.3706\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.7482 - acc: 0.3712 - val_loss: 1.7140 - val_acc: 0.3780\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.7406 - acc: 0.3758 - val_loss: 1.6256 - val_acc: 0.4143\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.7266 - acc: 0.3757 - val_loss: 1.6865 - val_acc: 0.3817\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.7311 - acc: 0.3768 - val_loss: 1.7414 - val_acc: 0.3765\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.7246 - acc: 0.3830 - val_loss: 1.7136 - val_acc: 0.3778\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.7093 - acc: 0.3883 - val_loss: 1.6767 - val_acc: 0.3887\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.7042 - acc: 0.3873 - val_loss: 1.6513 - val_acc: 0.4058\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.7016 - acc: 0.3896 - val_loss: 1.7518 - val_acc: 0.3644\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.6923 - acc: 0.3939 - val_loss: 1.5546 - val_acc: 0.4336\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.6850 - acc: 0.3975 - val_loss: 1.6173 - val_acc: 0.4070\n",
      "10000/10000 [==============================] - 1s 68us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 4\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 404,906\n",
      "Trainable params: 404,458\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 10s 195us/step - loss: 1.9038 - acc: 0.3132 - val_loss: 2.3484 - val_acc: 0.2536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.7600 - acc: 0.3700 - val_loss: 1.8834 - val_acc: 0.3123\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.7118 - acc: 0.3877 - val_loss: 1.7629 - val_acc: 0.3498\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.6847 - acc: 0.3937 - val_loss: 1.8036 - val_acc: 0.3561\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.6623 - acc: 0.4026 - val_loss: 1.6742 - val_acc: 0.3882\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.6353 - acc: 0.4105 - val_loss: 1.6673 - val_acc: 0.4070\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.6288 - acc: 0.4181 - val_loss: 1.6214 - val_acc: 0.4142\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.6194 - acc: 0.4196 - val_loss: 1.5985 - val_acc: 0.4267\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.6095 - acc: 0.4250 - val_loss: 1.5795 - val_acc: 0.4267\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.5971 - acc: 0.4265 - val_loss: 1.5430 - val_acc: 0.4463\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.5797 - acc: 0.4374 - val_loss: 1.5246 - val_acc: 0.4577\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.5762 - acc: 0.4377 - val_loss: 1.5152 - val_acc: 0.4544\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.5706 - acc: 0.4394 - val_loss: 1.5893 - val_acc: 0.4306\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.5651 - acc: 0.4426 - val_loss: 1.4992 - val_acc: 0.4585\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 8s 165us/step - loss: 1.5587 - acc: 0.4451 - val_loss: 1.7033 - val_acc: 0.3706\n",
      "10000/10000 [==============================] - 1s 71us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 5\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 830,282\n",
      "Trainable params: 829,386\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 18s 365us/step - loss: 1.8748 - acc: 0.3240 - val_loss: 1.8990 - val_acc: 0.3176\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.7034 - acc: 0.3884 - val_loss: 1.6187 - val_acc: 0.4202\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.6466 - acc: 0.4098 - val_loss: 1.6427 - val_acc: 0.4141\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.6162 - acc: 0.4223 - val_loss: 2.1248 - val_acc: 0.3119\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.5898 - acc: 0.4313 - val_loss: 1.5364 - val_acc: 0.4510\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.5648 - acc: 0.4394 - val_loss: 1.5962 - val_acc: 0.4319\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.5426 - acc: 0.4479 - val_loss: 1.6135 - val_acc: 0.4225\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.5304 - acc: 0.4533 - val_loss: 1.5270 - val_acc: 0.4503\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.5168 - acc: 0.4558 - val_loss: 1.5795 - val_acc: 0.4339\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.5127 - acc: 0.4573 - val_loss: 1.6752 - val_acc: 0.4057\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.5056 - acc: 0.4632 - val_loss: 1.4747 - val_acc: 0.4695\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.5026 - acc: 0.4650 - val_loss: 1.4755 - val_acc: 0.4701\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 1.4913 - acc: 0.4689 - val_loss: 1.5458 - val_acc: 0.4421\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.4701 - acc: 0.4771 - val_loss: 1.5601 - val_acc: 0.4489\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.4650 - acc: 0.4768 - val_loss: 1.5391 - val_acc: 0.4504\n",
      "10000/10000 [==============================] - 1s 96us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 6\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 64)                196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 199,898\n",
      "Trainable params: 199,674\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.0117 - acc: 0.2504 - val_loss: 1.9669 - val_acc: 0.2807\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.9205 - acc: 0.2963 - val_loss: 1.9015 - val_acc: 0.3327\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.8859 - acc: 0.3139 - val_loss: 1.8440 - val_acc: 0.3297\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.8620 - acc: 0.3265 - val_loss: 1.7579 - val_acc: 0.3530\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.8444 - acc: 0.3311 - val_loss: 1.7956 - val_acc: 0.3324\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.8199 - acc: 0.3431 - val_loss: 1.7645 - val_acc: 0.3619\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.8180 - acc: 0.3436 - val_loss: 1.7401 - val_acc: 0.3484\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.8024 - acc: 0.3513 - val_loss: 1.7821 - val_acc: 0.3562\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.7967 - acc: 0.3556 - val_loss: 1.7379 - val_acc: 0.3567\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.7911 - acc: 0.3583 - val_loss: 1.9366 - val_acc: 0.3478\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.7784 - acc: 0.3614 - val_loss: 1.7425 - val_acc: 0.3680\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.7665 - acc: 0.3666 - val_loss: 1.7480 - val_acc: 0.3726\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.7646 - acc: 0.3662 - val_loss: 1.7789 - val_acc: 0.3616\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.7618 - acc: 0.3669 - val_loss: 1.7335 - val_acc: 0.3773\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.7571 - acc: 0.3719 - val_loss: 1.8488 - val_acc: 0.3382\n",
      "10000/10000 [==============================] - 1s 67us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 7\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_8 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 404,906\n",
      "Trainable params: 404,458\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 10s 198us/step - loss: 2.0101 - acc: 0.2630 - val_loss: 2.0304 - val_acc: 0.2901\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.8956 - acc: 0.3091 - val_loss: 1.8908 - val_acc: 0.3271\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.8489 - acc: 0.3347 - val_loss: 1.7931 - val_acc: 0.3654\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.8272 - acc: 0.3435 - val_loss: 1.7113 - val_acc: 0.3810\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.7927 - acc: 0.3580 - val_loss: 1.7605 - val_acc: 0.3618\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.7660 - acc: 0.3695 - val_loss: 1.7505 - val_acc: 0.3807\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.7580 - acc: 0.3732 - val_loss: 2.1634 - val_acc: 0.2834\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.7521 - acc: 0.3759 - val_loss: 1.8721 - val_acc: 0.3292\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.7364 - acc: 0.3813 - val_loss: 1.8830 - val_acc: 0.3429\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.7315 - acc: 0.3825 - val_loss: 1.7128 - val_acc: 0.3795\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.7367 - acc: 0.3806 - val_loss: 1.6945 - val_acc: 0.3791\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.7139 - acc: 0.3883 - val_loss: 1.7653 - val_acc: 0.3636\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 8s 168us/step - loss: 1.7040 - acc: 0.3931 - val_loss: 1.6350 - val_acc: 0.4130\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.6964 - acc: 0.3925 - val_loss: 1.7173 - val_acc: 0.3880\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.6918 - acc: 0.3978 - val_loss: 1.6824 - val_acc: 0.4082\n",
      "10000/10000 [==============================] - 1s 75us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 8\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_9 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 830,282\n",
      "Trainable params: 829,386\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 14s 287us/step - loss: 2.0054 - acc: 0.2681 - val_loss: 1.9806 - val_acc: 0.3189\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 1.8835 - acc: 0.3188 - val_loss: 1.7552 - val_acc: 0.3669\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 14s 276us/step - loss: 1.8288 - acc: 0.3431 - val_loss: 1.8401 - val_acc: 0.3367\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 14s 271us/step - loss: 1.8115 - acc: 0.3528 - val_loss: 1.9750 - val_acc: 0.3479\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 14s 277us/step - loss: 1.7695 - acc: 0.3685 - val_loss: 1.8963 - val_acc: 0.3412\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 14s 278us/step - loss: 1.7439 - acc: 0.3788 - val_loss: 1.8507 - val_acc: 0.3700\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 1.7481 - acc: 0.3795 - val_loss: 1.8308 - val_acc: 0.3623\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 13s 270us/step - loss: 1.7362 - acc: 0.3835 - val_loss: 1.7996 - val_acc: 0.3620\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.7251 - acc: 0.3890 - val_loss: 1.8951 - val_acc: 0.3630\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 14s 270us/step - loss: 1.7120 - acc: 0.3951 - val_loss: 1.6765 - val_acc: 0.4098\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.7018 - acc: 0.3987 - val_loss: 2.0282 - val_acc: 0.3102\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 1.7082 - acc: 0.3988 - val_loss: 1.7961 - val_acc: 0.3769\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 1.7117 - acc: 0.3927 - val_loss: 1.9375 - val_acc: 0.3093\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 1.7030 - acc: 0.3941 - val_loss: 1.6452 - val_acc: 0.4017\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.6765 - acc: 0.4124 - val_loss: 1.6257 - val_acc: 0.4174\n",
      "10000/10000 [==============================] - 1s 88us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 9\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_10 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 64)                196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 199,898\n",
      "Trainable params: 199,674\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.2311 - acc: 0.2019 - val_loss: 1.9224 - val_acc: 0.2828\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 2.0028 - acc: 0.2588 - val_loss: 1.9481 - val_acc: 0.2749\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.9519 - acc: 0.2788 - val_loss: 1.8425 - val_acc: 0.3439\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.9342 - acc: 0.2895 - val_loss: 1.9296 - val_acc: 0.2924\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.9199 - acc: 0.2958 - val_loss: 1.8031 - val_acc: 0.3418\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.9066 - acc: 0.3025 - val_loss: 1.8399 - val_acc: 0.3211\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.8959 - acc: 0.3087 - val_loss: 1.7933 - val_acc: 0.3553\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.8812 - acc: 0.3118 - val_loss: 1.7522 - val_acc: 0.3746\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.8760 - acc: 0.3151 - val_loss: 1.7461 - val_acc: 0.3760\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.8719 - acc: 0.3242 - val_loss: 1.7983 - val_acc: 0.3508\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.8623 - acc: 0.3244 - val_loss: 1.7697 - val_acc: 0.3553\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.8623 - acc: 0.3243 - val_loss: 1.7326 - val_acc: 0.3816\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.8553 - acc: 0.3303 - val_loss: 1.7333 - val_acc: 0.3769\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.8623 - acc: 0.3232 - val_loss: 1.7525 - val_acc: 0.3695\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.8466 - acc: 0.3326 - val_loss: 1.7100 - val_acc: 0.3845\n",
      "10000/10000 [==============================] - 1s 69us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 10\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_11 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 404,906\n",
      "Trainable params: 404,458\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 10s 209us/step - loss: 2.1863 - acc: 0.2383 - val_loss: 1.9730 - val_acc: 0.2671\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.9096 - acc: 0.3057 - val_loss: 1.8099 - val_acc: 0.3457\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.8486 - acc: 0.3313 - val_loss: 1.7438 - val_acc: 0.3609\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.8157 - acc: 0.3443 - val_loss: 1.8193 - val_acc: 0.3552\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.8106 - acc: 0.3491 - val_loss: 1.7406 - val_acc: 0.3663\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.7928 - acc: 0.3567 - val_loss: 1.6709 - val_acc: 0.3969\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.7871 - acc: 0.3562 - val_loss: 1.6904 - val_acc: 0.3852\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.7857 - acc: 0.3564 - val_loss: 1.6927 - val_acc: 0.3889\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.7729 - acc: 0.3656 - val_loss: 1.7092 - val_acc: 0.3761\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.7616 - acc: 0.3682 - val_loss: 1.6555 - val_acc: 0.3992\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.7553 - acc: 0.3711 - val_loss: 1.7044 - val_acc: 0.4007\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 9s 170us/step - loss: 1.7550 - acc: 0.3727 - val_loss: 1.6289 - val_acc: 0.4123\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 1.7464 - acc: 0.3744 - val_loss: 1.6108 - val_acc: 0.4271\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.7392 - acc: 0.3775 - val_loss: 1.6141 - val_acc: 0.4206\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.7355 - acc: 0.3803 - val_loss: 1.6241 - val_acc: 0.4144\n",
      "10000/10000 [==============================] - 1s 74us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 11\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_12 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 830,282\n",
      "Trainable params: 829,386\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 15s 292us/step - loss: 2.1129 - acc: 0.2700 - val_loss: 1.8194 - val_acc: 0.3542\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.8261 - acc: 0.3431 - val_loss: 1.7282 - val_acc: 0.3681\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.7614 - acc: 0.3665 - val_loss: 1.7286 - val_acc: 0.3760\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.7469 - acc: 0.3742 - val_loss: 1.6585 - val_acc: 0.4011\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.7199 - acc: 0.3836 - val_loss: 1.6716 - val_acc: 0.3964\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 1.7002 - acc: 0.3941 - val_loss: 1.5881 - val_acc: 0.4382\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 1.6939 - acc: 0.3917 - val_loss: 1.6275 - val_acc: 0.4113\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 13s 256us/step - loss: 1.6739 - acc: 0.4029 - val_loss: 1.6489 - val_acc: 0.3986\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.6650 - acc: 0.4046 - val_loss: 1.6795 - val_acc: 0.4074\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.6597 - acc: 0.4066 - val_loss: 1.5366 - val_acc: 0.4540\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.6436 - acc: 0.4123 - val_loss: 1.5307 - val_acc: 0.4423\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.6375 - acc: 0.4153 - val_loss: 1.5742 - val_acc: 0.4344\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.6471 - acc: 0.4133 - val_loss: 1.5666 - val_acc: 0.4419\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.6323 - acc: 0.4189 - val_loss: 1.5406 - val_acc: 0.4387\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.6415 - acc: 0.4141 - val_loss: 1.5962 - val_acc: 0.4270\n",
      "10000/10000 [==============================] - 1s 92us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 12\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_13 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_49 (Dense)             (None, 64)                196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 199,898\n",
      "Trainable params: 199,674\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 2.0415 - acc: 0.2501 - val_loss: 1.8563 - val_acc: 0.3114\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.9292 - acc: 0.2962 - val_loss: 1.8659 - val_acc: 0.3125\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.8984 - acc: 0.3103 - val_loss: 1.8111 - val_acc: 0.3307\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.8843 - acc: 0.3195 - val_loss: 1.7929 - val_acc: 0.3487\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.8678 - acc: 0.3239 - val_loss: 1.7419 - val_acc: 0.3654\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.8660 - acc: 0.3274 - val_loss: 1.7627 - val_acc: 0.3566\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.8559 - acc: 0.3279 - val_loss: 1.8008 - val_acc: 0.3445\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.8546 - acc: 0.3307 - val_loss: 1.8318 - val_acc: 0.3236\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.8548 - acc: 0.3287 - val_loss: 1.8995 - val_acc: 0.2844\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.8421 - acc: 0.3342 - val_loss: 1.7592 - val_acc: 0.3645\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.8345 - acc: 0.3413 - val_loss: 1.6988 - val_acc: 0.3853\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.8336 - acc: 0.3417 - val_loss: 1.7378 - val_acc: 0.3732\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.8280 - acc: 0.3429 - val_loss: 1.6739 - val_acc: 0.3987\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.8232 - acc: 0.3456 - val_loss: 1.7053 - val_acc: 0.3883\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.8206 - acc: 0.3480 - val_loss: 1.6915 - val_acc: 0.3886\n",
      "10000/10000 [==============================] - 1s 70us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 13\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_14 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_41 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_42 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_42 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 404,906\n",
      "Trainable params: 404,458\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 1.9999 - acc: 0.2722 - val_loss: 1.8867 - val_acc: 0.3229\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.8741 - acc: 0.3207 - val_loss: 1.7975 - val_acc: 0.3536\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.8365 - acc: 0.3365 - val_loss: 1.7274 - val_acc: 0.3799\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.8240 - acc: 0.3441 - val_loss: 1.8151 - val_acc: 0.3547\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.8060 - acc: 0.3523 - val_loss: 1.7874 - val_acc: 0.3396\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.7926 - acc: 0.3555 - val_loss: 1.7150 - val_acc: 0.3802\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.7827 - acc: 0.3606 - val_loss: 1.6717 - val_acc: 0.3984\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.7703 - acc: 0.3693 - val_loss: 1.6798 - val_acc: 0.3959\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.7725 - acc: 0.3662 - val_loss: 1.6300 - val_acc: 0.4134\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.7757 - acc: 0.3677 - val_loss: 1.6602 - val_acc: 0.4059\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.7717 - acc: 0.3659 - val_loss: 1.6957 - val_acc: 0.3933\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.7714 - acc: 0.3667 - val_loss: 1.6278 - val_acc: 0.4154\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.7671 - acc: 0.3718 - val_loss: 1.7220 - val_acc: 0.3764\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.7654 - acc: 0.3681 - val_loss: 1.7256 - val_acc: 0.3829\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.7655 - acc: 0.3701 - val_loss: 1.6820 - val_acc: 0.3954\n",
      "10000/10000 [==============================] - 1s 78us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 14\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_15 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_43 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_43 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_44 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_45 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 830,282\n",
      "Trainable params: 829,386\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 21s 414us/step - loss: 1.9536 - acc: 0.2966 - val_loss: 1.9009 - val_acc: 0.3130\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 1.7969 - acc: 0.3517 - val_loss: 1.8201 - val_acc: 0.3368\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 14s 277us/step - loss: 1.7639 - acc: 0.3671 - val_loss: 1.7971 - val_acc: 0.3442\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 15s 294us/step - loss: 1.7455 - acc: 0.3755 - val_loss: 1.7243 - val_acc: 0.3756\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.7314 - acc: 0.3830 - val_loss: 1.7984 - val_acc: 0.3412\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 15s 308us/step - loss: 1.7252 - acc: 0.3842 - val_loss: 1.7053 - val_acc: 0.3982\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 1.7142 - acc: 0.3857 - val_loss: 1.6165 - val_acc: 0.4219\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 1.7047 - acc: 0.3910 - val_loss: 1.6073 - val_acc: 0.4263\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 1.6835 - acc: 0.4000 - val_loss: 1.5627 - val_acc: 0.4458\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 13s 255us/step - loss: 1.6780 - acc: 0.4023 - val_loss: 1.5719 - val_acc: 0.4372\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.6640 - acc: 0.4039 - val_loss: 1.7067 - val_acc: 0.3748\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.6670 - acc: 0.4027 - val_loss: 1.5403 - val_acc: 0.4420\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.6549 - acc: 0.4086 - val_loss: 1.5850 - val_acc: 0.4388\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.6576 - acc: 0.4112 - val_loss: 1.5783 - val_acc: 0.4366\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.6636 - acc: 0.4060 - val_loss: 1.6453 - val_acc: 0.4024\n",
      "10000/10000 [==============================] - 1s 89us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 15\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_16 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 64)                196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_46 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_47 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_48 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 199,898\n",
      "Trainable params: 199,674\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 8s 160us/step - loss: 2.1170 - acc: 0.2038 - val_loss: 1.9775 - val_acc: 0.2649\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 2.0247 - acc: 0.2412 - val_loss: 2.0080 - val_acc: 0.2385\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 2.0106 - acc: 0.2502 - val_loss: 1.8826 - val_acc: 0.2626\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.9772 - acc: 0.2671 - val_loss: 1.8765 - val_acc: 0.2988\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.9633 - acc: 0.2748 - val_loss: 1.8361 - val_acc: 0.3273\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.9477 - acc: 0.2840 - val_loss: 1.8352 - val_acc: 0.3288\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.9461 - acc: 0.2856 - val_loss: 1.8880 - val_acc: 0.2830\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.9331 - acc: 0.2911 - val_loss: 1.8639 - val_acc: 0.3174\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.9249 - acc: 0.2951 - val_loss: 1.9016 - val_acc: 0.3001\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.9182 - acc: 0.2952 - val_loss: 1.7656 - val_acc: 0.3562\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.9200 - acc: 0.2985 - val_loss: 1.7883 - val_acc: 0.3449\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.9206 - acc: 0.2968 - val_loss: 1.8311 - val_acc: 0.3366\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.9305 - acc: 0.2930 - val_loss: 1.8554 - val_acc: 0.3131\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.9183 - acc: 0.2971 - val_loss: 1.8201 - val_acc: 0.3255\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.9081 - acc: 0.3008 - val_loss: 1.7293 - val_acc: 0.3677\n",
      "10000/10000 [==============================] - 1s 72us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 16\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_17 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_49 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 404,906\n",
      "Trainable params: 404,458\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 11s 219us/step - loss: 2.0719 - acc: 0.2287 - val_loss: 1.8989 - val_acc: 0.3048\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.9834 - acc: 0.2721 - val_loss: 1.8780 - val_acc: 0.3183\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.9451 - acc: 0.2880 - val_loss: 1.9181 - val_acc: 0.2918\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 9s 180us/step - loss: 1.9297 - acc: 0.2972 - val_loss: 1.8344 - val_acc: 0.3562\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.9152 - acc: 0.3062 - val_loss: 1.8138 - val_acc: 0.3476\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.9232 - acc: 0.2991 - val_loss: 1.9393 - val_acc: 0.3016\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.9147 - acc: 0.3056 - val_loss: 1.8548 - val_acc: 0.3037\n",
      "Epoch 8/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 8s 169us/step - loss: 1.8979 - acc: 0.3101 - val_loss: 1.7886 - val_acc: 0.3353\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 9s 171us/step - loss: 1.8919 - acc: 0.3147 - val_loss: 1.8173 - val_acc: 0.3546\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.8841 - acc: 0.3197 - val_loss: 1.7486 - val_acc: 0.3749\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.8866 - acc: 0.3188 - val_loss: 1.7856 - val_acc: 0.3414\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.8620 - acc: 0.3331 - val_loss: 1.7397 - val_acc: 0.3623\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 9s 173us/step - loss: 1.8470 - acc: 0.3376 - val_loss: 1.6615 - val_acc: 0.4030\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 9s 174us/step - loss: 1.8473 - acc: 0.3366 - val_loss: 1.7489 - val_acc: 0.3772\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 9s 172us/step - loss: 1.8440 - acc: 0.3379 - val_loss: 1.7004 - val_acc: 0.3943\n",
      "10000/10000 [==============================] - 1s 75us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 17\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_18 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_52 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_52 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_53 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_53 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_54 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_54 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 830,282\n",
      "Trainable params: 829,386\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 15s 303us/step - loss: 2.0748 - acc: 0.2377 - val_loss: 2.3134 - val_acc: 0.2327\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.9783 - acc: 0.2821 - val_loss: 1.8242 - val_acc: 0.3364\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.9247 - acc: 0.3089 - val_loss: 1.8193 - val_acc: 0.3509\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.9128 - acc: 0.3155 - val_loss: 1.7146 - val_acc: 0.3806\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.9005 - acc: 0.3181 - val_loss: 1.9125 - val_acc: 0.3565\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 1.8613 - acc: 0.3339 - val_loss: 1.7178 - val_acc: 0.3873\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.8566 - acc: 0.3361 - val_loss: 1.7257 - val_acc: 0.3778\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.8728 - acc: 0.3297 - val_loss: 1.8029 - val_acc: 0.3453\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 13s 255us/step - loss: 1.8395 - acc: 0.3430 - val_loss: 1.7543 - val_acc: 0.3603\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 13s 255us/step - loss: 1.8383 - acc: 0.3440 - val_loss: 1.7444 - val_acc: 0.3802\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 1.8266 - acc: 0.3517 - val_loss: 1.7204 - val_acc: 0.3884\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.8245 - acc: 0.3522 - val_loss: 1.7264 - val_acc: 0.3708\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.8338 - acc: 0.3480 - val_loss: 1.7925 - val_acc: 0.3383\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.8454 - acc: 0.3396 - val_loss: 1.8811 - val_acc: 0.3276\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.8308 - acc: 0.3469 - val_loss: 1.6380 - val_acc: 0.4043\n",
      "10000/10000 [==============================] - 1s 93us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 18\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_19 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 64)                196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_55 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_55 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_56 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_56 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_57 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_57 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 199,898\n",
      "Trainable params: 199,674\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 8s 170us/step - loss: 2.3893 - acc: 0.1709 - val_loss: 2.0558 - val_acc: 0.2273\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 2.0901 - acc: 0.2202 - val_loss: 1.9223 - val_acc: 0.3167\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 2.0392 - acc: 0.2382 - val_loss: 1.9260 - val_acc: 0.2837\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 2.0174 - acc: 0.2413 - val_loss: 1.9467 - val_acc: 0.3082\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 2.0085 - acc: 0.2541 - val_loss: 1.9397 - val_acc: 0.2783\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.9884 - acc: 0.2600 - val_loss: 1.8643 - val_acc: 0.3229\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.9882 - acc: 0.2620 - val_loss: 1.9191 - val_acc: 0.2956\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.9879 - acc: 0.2568 - val_loss: 1.8590 - val_acc: 0.3278\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.9860 - acc: 0.2577 - val_loss: 1.9090 - val_acc: 0.2895\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.9804 - acc: 0.2580 - val_loss: 1.8847 - val_acc: 0.3026\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.9796 - acc: 0.2593 - val_loss: 1.8629 - val_acc: 0.3158\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.9836 - acc: 0.2555 - val_loss: 1.8594 - val_acc: 0.3270\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.9742 - acc: 0.2574 - val_loss: 1.9022 - val_acc: 0.2848\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.9702 - acc: 0.2587 - val_loss: 1.8540 - val_acc: 0.3264\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 6s 116us/step - loss: 1.9695 - acc: 0.2647 - val_loss: 1.8473 - val_acc: 0.3220\n",
      "10000/10000 [==============================] - 1s 69us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 19\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_20 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_58 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_59 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_59 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_60 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_60 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 404,906\n",
      "Trainable params: 404,458\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 2.3790 - acc: 0.1909 - val_loss: 1.9394 - val_acc: 0.2774\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 2.0177 - acc: 0.2560 - val_loss: 1.8690 - val_acc: 0.3163\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.9522 - acc: 0.2812 - val_loss: 1.8668 - val_acc: 0.3181\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.9339 - acc: 0.2919 - val_loss: 1.9075 - val_acc: 0.2921\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.9233 - acc: 0.2985 - val_loss: 1.8433 - val_acc: 0.3257\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.9081 - acc: 0.3020 - val_loss: 1.7882 - val_acc: 0.3518\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 9s 175us/step - loss: 1.9019 - acc: 0.3074 - val_loss: 1.7921 - val_acc: 0.3426\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.8951 - acc: 0.3093 - val_loss: 1.7883 - val_acc: 0.3352\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 9s 178us/step - loss: 1.8955 - acc: 0.3084 - val_loss: 1.7830 - val_acc: 0.3478\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 9s 179us/step - loss: 1.8829 - acc: 0.3154 - val_loss: 1.8527 - val_acc: 0.3365\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.8861 - acc: 0.3087 - val_loss: 1.7642 - val_acc: 0.3542\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.8895 - acc: 0.3118 - val_loss: 1.7927 - val_acc: 0.3440\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.8829 - acc: 0.3152 - val_loss: 1.7789 - val_acc: 0.3459\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 9s 176us/step - loss: 1.8846 - acc: 0.3116 - val_loss: 1.7839 - val_acc: 0.3545\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 9s 177us/step - loss: 1.8787 - acc: 0.3111 - val_loss: 1.7603 - val_acc: 0.3588\n",
      "10000/10000 [==============================] - 1s 77us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 20\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_21 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_61 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_62 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_63 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 830,282\n",
      "Trainable params: 829,386\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 16s 319us/step - loss: 2.3542 - acc: 0.2214 - val_loss: 1.9036 - val_acc: 0.3102\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.9478 - acc: 0.2930 - val_loss: 1.8362 - val_acc: 0.3382\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 1.8755 - acc: 0.3197 - val_loss: 1.8033 - val_acc: 0.3484\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.8512 - acc: 0.3343 - val_loss: 1.7606 - val_acc: 0.3539\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.8389 - acc: 0.3385 - val_loss: 1.7324 - val_acc: 0.3856\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 1.8299 - acc: 0.3392 - val_loss: 1.6945 - val_acc: 0.3948\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 1.8254 - acc: 0.3443 - val_loss: 1.7375 - val_acc: 0.3729\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.8364 - acc: 0.3352 - val_loss: 1.7262 - val_acc: 0.3692\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 14s 277us/step - loss: 1.8175 - acc: 0.3486 - val_loss: 1.7117 - val_acc: 0.3822\n",
      "Epoch 10/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 15s 292us/step - loss: 1.8049 - acc: 0.3536 - val_loss: 1.6793 - val_acc: 0.3984\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.7983 - acc: 0.3557 - val_loss: 1.6815 - val_acc: 0.3953 1s - loss: \n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.7933 - acc: 0.3562 - val_loss: 1.6834 - val_acc: 0.3882\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 18s 353us/step - loss: 1.7856 - acc: 0.3569 - val_loss: 1.7224 - val_acc: 0.3608\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 1.7833 - acc: 0.3610 - val_loss: 1.6543 - val_acc: 0.4129\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 16s 326us/step - loss: 1.7920 - acc: 0.3564 - val_loss: 1.6488 - val_acc: 0.4046\n",
      "10000/10000 [==============================] - 1s 125us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 21\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_22 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 64)                196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_64 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_65 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_65 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_66 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_66 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 199,898\n",
      "Trainable params: 199,674\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 18s 357us/step - loss: 2.1359 - acc: 0.2024 - val_loss: 2.0150 - val_acc: 0.2642\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 9s 181us/step - loss: 2.0116 - acc: 0.2469 - val_loss: 1.8744 - val_acc: 0.2999\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.9907 - acc: 0.2534 - val_loss: 1.8708 - val_acc: 0.3095\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.9900 - acc: 0.2530 - val_loss: 1.8976 - val_acc: 0.2825\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.9785 - acc: 0.2542 - val_loss: 1.8903 - val_acc: 0.2910\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 8s 164us/step - loss: 1.9829 - acc: 0.2488 - val_loss: 1.8560 - val_acc: 0.3079\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.9765 - acc: 0.2606 - val_loss: 1.8500 - val_acc: 0.3021\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.9620 - acc: 0.2666 - val_loss: 1.8302 - val_acc: 0.3212\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.9490 - acc: 0.2718 - val_loss: 1.8988 - val_acc: 0.2867\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.9497 - acc: 0.2758 - val_loss: 1.8595 - val_acc: 0.3101\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.9495 - acc: 0.2779 - val_loss: 1.8373 - val_acc: 0.3392\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 8s 162us/step - loss: 1.9458 - acc: 0.2794 - val_loss: 1.8368 - val_acc: 0.3328\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.9480 - acc: 0.2803 - val_loss: 1.8105 - val_acc: 0.3503\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.9488 - acc: 0.2811 - val_loss: 1.8196 - val_acc: 0.3277\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.9415 - acc: 0.2804 - val_loss: 1.8204 - val_acc: 0.3324\n",
      "10000/10000 [==============================] - 1s 100us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 22\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_23 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_67 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_67 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_68 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_68 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_69 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_92 (Dense)             (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 404,906\n",
      "Trainable params: 404,458\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 22s 435us/step - loss: 2.0887 - acc: 0.2331 - val_loss: 1.8803 - val_acc: 0.3019\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 1.9485 - acc: 0.2813 - val_loss: 1.8368 - val_acc: 0.3201\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 1.9232 - acc: 0.2950 - val_loss: 1.8067 - val_acc: 0.3393\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 1.9166 - acc: 0.2998 - val_loss: 1.8991 - val_acc: 0.2993\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 1.9030 - acc: 0.3059 - val_loss: 1.8011 - val_acc: 0.3373\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 12s 242us/step - loss: 1.8884 - acc: 0.3136 - val_loss: 1.8692 - val_acc: 0.3224\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 1.8843 - acc: 0.3143 - val_loss: 1.8081 - val_acc: 0.3394\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 1.8856 - acc: 0.3108 - val_loss: 1.7908 - val_acc: 0.3445\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 12s 238us/step - loss: 1.8874 - acc: 0.3136 - val_loss: 1.7571 - val_acc: 0.3635\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 1.8747 - acc: 0.3188 - val_loss: 1.7322 - val_acc: 0.3688\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 1.8764 - acc: 0.3200 - val_loss: 1.7987 - val_acc: 0.3361\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.8867 - acc: 0.3155 - val_loss: 1.7932 - val_acc: 0.3412\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 11s 218us/step - loss: 1.8871 - acc: 0.3142 - val_loss: 1.7994 - val_acc: 0.3386\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 11s 221us/step - loss: 1.8794 - acc: 0.3171 - val_loss: 1.7430 - val_acc: 0.3731\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 11s 224us/step - loss: 1.8796 - acc: 0.3176 - val_loss: 1.7333 - val_acc: 0.3760\n",
      "10000/10000 [==============================] - 1s 128us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 23\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_24 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_93 (Dense)             (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_70 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_94 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_71 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_95 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_72 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_96 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 830,282\n",
      "Trainable params: 829,386\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 23s 459us/step - loss: 2.0342 - acc: 0.2654 - val_loss: 1.8172 - val_acc: 0.3524\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 18s 359us/step - loss: 1.8864 - acc: 0.3182 - val_loss: 1.7648 - val_acc: 0.3641\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 1.8676 - acc: 0.3244 - val_loss: 1.9808 - val_acc: 0.2608\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 23s 455us/step - loss: 1.8657 - acc: 0.3243 - val_loss: 1.7687 - val_acc: 0.3704\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 22s 446us/step - loss: 1.8503 - acc: 0.3319 - val_loss: 1.7499 - val_acc: 0.3608\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 22s 440us/step - loss: 1.8334 - acc: 0.3397 - val_loss: 1.7825 - val_acc: 0.3651\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 22s 435us/step - loss: 1.8195 - acc: 0.3448 - val_loss: 1.8046 - val_acc: 0.3444\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 22s 435us/step - loss: 1.8160 - acc: 0.3457 - val_loss: 1.6654 - val_acc: 0.4027\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 22s 435us/step - loss: 1.8156 - acc: 0.3481 - val_loss: 1.7849 - val_acc: 0.3685\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 22s 439us/step - loss: 1.8091 - acc: 0.3526 - val_loss: 1.6584 - val_acc: 0.4086\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 22s 441us/step - loss: 1.8021 - acc: 0.3570 - val_loss: 1.6942 - val_acc: 0.3892\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 22s 435us/step - loss: 1.8017 - acc: 0.3520 - val_loss: 1.6692 - val_acc: 0.4055\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 22s 433us/step - loss: 1.7897 - acc: 0.3582 - val_loss: 1.6530 - val_acc: 0.4053\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 22s 435us/step - loss: 1.7872 - acc: 0.3623 - val_loss: 1.6396 - val_acc: 0.4159\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 22s 441us/step - loss: 1.7861 - acc: 0.3581 - val_loss: 1.6387 - val_acc: 0.4117\n",
      "10000/10000 [==============================] - 2s 157us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 24\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_25 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_97 (Dense)             (None, 64)                196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_73 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_73 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_74 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_99 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_75 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_100 (Dense)            (None, 10)                170       \n",
      "=================================================================\n",
      "Total params: 199,898\n",
      "Trainable params: 199,674\n",
      "Non-trainable params: 224\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 17s 333us/step - loss: 2.1749 - acc: 0.1745 - val_loss: 2.0422 - val_acc: 0.2129\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 11s 212us/step - loss: 2.1008 - acc: 0.1994 - val_loss: 1.9711 - val_acc: 0.2492\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 11s 215us/step - loss: 2.0833 - acc: 0.2046 - val_loss: 1.9956 - val_acc: 0.1979\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 2.0725 - acc: 0.2096 - val_loss: 1.9925 - val_acc: 0.2170\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 11s 217us/step - loss: 2.0739 - acc: 0.2055 - val_loss: 1.9685 - val_acc: 0.2173\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 11s 214us/step - loss: 2.0727 - acc: 0.2098 - val_loss: 1.9420 - val_acc: 0.2448\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 11s 210us/step - loss: 2.0639 - acc: 0.2127 - val_loss: 2.0829 - val_acc: 0.1951\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 9s 187us/step - loss: 2.0761 - acc: 0.2074 - val_loss: 1.9682 - val_acc: 0.2196\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 2.0706 - acc: 0.2099 - val_loss: 1.9978 - val_acc: 0.2296\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.0667 - acc: 0.2123 - val_loss: 1.9746 - val_acc: 0.2275\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 2.0561 - acc: 0.2142 - val_loss: 1.9647 - val_acc: 0.2441\n",
      "Epoch 12/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 7s 147us/step - loss: 2.0625 - acc: 0.2106 - val_loss: 1.9635 - val_acc: 0.2298\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.0753 - acc: 0.2060 - val_loss: 1.9622 - val_acc: 0.2450\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.0632 - acc: 0.2138 - val_loss: 1.9332 - val_acc: 0.2254\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.0623 - acc: 0.2088 - val_loss: 1.9661 - val_acc: 0.2273\n",
      "10000/10000 [==============================] - 1s 88us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 25\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_26 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_101 (Dense)            (None, 128)               393344    \n",
      "_________________________________________________________________\n",
      "batch_normalization_76 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_76 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_102 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_77 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_103 (Dense)            (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_78 (Batc (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 404,906\n",
      "Trainable params: 404,458\n",
      "Non-trainable params: 448\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 22s 438us/step - loss: 2.1752 - acc: 0.1853 - val_loss: 2.0445 - val_acc: 0.2444\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 15s 305us/step - loss: 2.0758 - acc: 0.2254 - val_loss: 1.8902 - val_acc: 0.2957\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 2.0414 - acc: 0.2401 - val_loss: 1.9405 - val_acc: 0.2809\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 12s 250us/step - loss: 2.0350 - acc: 0.2387 - val_loss: 1.9009 - val_acc: 0.2877\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 2.0261 - acc: 0.2416 - val_loss: 1.9120 - val_acc: 0.2690\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 12s 236us/step - loss: 2.0303 - acc: 0.2421 - val_loss: 2.0101 - val_acc: 0.2453\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 2.0129 - acc: 0.2556 - val_loss: 1.9993 - val_acc: 0.2660\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 12s 236us/step - loss: 2.0204 - acc: 0.2568 - val_loss: 1.9925 - val_acc: 0.2675\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 2.0006 - acc: 0.2594 - val_loss: 1.8901 - val_acc: 0.2724\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 1.9987 - acc: 0.2640 - val_loss: 1.8258 - val_acc: 0.3056\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 12s 234us/step - loss: 1.9932 - acc: 0.2652 - val_loss: 1.8446 - val_acc: 0.3246\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 12s 237us/step - loss: 1.9926 - acc: 0.2689 - val_loss: 1.8679 - val_acc: 0.3151\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 1.9953 - acc: 0.2649 - val_loss: 1.9022 - val_acc: 0.2927\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 12s 235us/step - loss: 1.9889 - acc: 0.2663 - val_loss: 1.8072 - val_acc: 0.3251\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 12s 236us/step - loss: 1.9805 - acc: 0.2695 - val_loss: 1.8869 - val_acc: 0.2930\n",
      "10000/10000 [==============================] - 1s 111us/step\n",
      "\n",
      "ROUND WITH PARAMETERS:%d 26\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_27 (Flatten)         (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_105 (Dense)            (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_79 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_106 (Dense)            (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_80 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_80 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_107 (Dense)            (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_81 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_81 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_108 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 830,282\n",
      "Trainable params: 829,386\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "50000/50000 [==============================] - 27s 544us/step - loss: 2.1671 - acc: 0.1991 - val_loss: 1.9179 - val_acc: 0.2957\n",
      "Epoch 2/15\n",
      "50000/50000 [==============================] - 18s 354us/step - loss: 2.0639 - acc: 0.2383 - val_loss: 1.9845 - val_acc: 0.2841\n",
      "Epoch 3/15\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 2.0351 - acc: 0.2588 - val_loss: 1.8939 - val_acc: 0.3251\n",
      "Epoch 4/15\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 2.0139 - acc: 0.2642 - val_loss: 1.8211 - val_acc: 0.3309\n",
      "Epoch 5/15\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 2.0028 - acc: 0.2721 - val_loss: 1.8315 - val_acc: 0.3212\n",
      "Epoch 6/15\n",
      "50000/50000 [==============================] - 17s 338us/step - loss: 1.9879 - acc: 0.2816 - val_loss: 1.9306 - val_acc: 0.3035\n",
      "Epoch 7/15\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 1.9786 - acc: 0.2863 - val_loss: 1.8494 - val_acc: 0.3311\n",
      "Epoch 8/15\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 1.9855 - acc: 0.2826 - val_loss: 1.7494 - val_acc: 0.3656\n",
      "Epoch 9/15\n",
      "50000/50000 [==============================] - 17s 342us/step - loss: 1.9886 - acc: 0.2805 - val_loss: 1.8661 - val_acc: 0.3188\n",
      "Epoch 10/15\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 1.9770 - acc: 0.2894 - val_loss: 1.8771 - val_acc: 0.3176\n",
      "Epoch 11/15\n",
      "50000/50000 [==============================] - 17s 340us/step - loss: 1.9584 - acc: 0.2920 - val_loss: 1.8164 - val_acc: 0.3160\n",
      "Epoch 12/15\n",
      "50000/50000 [==============================] - 17s 339us/step - loss: 1.9547 - acc: 0.2940 - val_loss: 1.7816 - val_acc: 0.3528\n",
      "Epoch 13/15\n",
      "50000/50000 [==============================] - 16s 313us/step - loss: 1.9500 - acc: 0.2976 - val_loss: 1.8176 - val_acc: 0.3422\n",
      "Epoch 14/15\n",
      "50000/50000 [==============================] - 16s 315us/step - loss: 1.9528 - acc: 0.2983 - val_loss: 1.9146 - val_acc: 0.3115\n",
      "Epoch 15/15\n",
      "50000/50000 [==============================] - 16s 316us/step - loss: 1.9597 - acc: 0.2952 - val_loss: 1.7761 - val_acc: 0.3453\n",
      "10000/10000 [==============================] - 1s 124us/step\n",
      "OOB: 0.47510\n",
      "Grid: {'learn_rate': 0.001, 'epochs': 15, 'dropout_rate': 0.2, 'neurons': 256}\n"
     ]
    }
   ],
   "source": [
    "epochs = [15]\n",
    "dropout_rate = [0.2,0.35,0.5]\n",
    "learn_rate = [0.001,0.01,0.1]\n",
    "neurons = [64,128,256]\n",
    "model = KerasClassifier(build_fn=create_model,verbose=1)\n",
    "param_grid = dict(epochs=epochs,dropout_rate=dropout_rate,learn_rate=learn_rate,neurons=neurons)\n",
    "#para_grid=dict(neurons=neurons)\n",
    "best_score=0\n",
    "best_grid=param_grid\n",
    "all_grids=[]\n",
    "all_scores=[]\n",
    "counter=0\n",
    "\n",
    "for g in ParameterGrid(param_grid):\n",
    "    print()\n",
    "    print('ROUND WITH PARAMETERS:%d',counter)\n",
    "    print()\n",
    "    counter=counter+1\n",
    "    model.set_params(**g)\n",
    "    model.fit(x_train,y_train,batch_size=128,validation_data=(x_test,y_test))\n",
    "    score = model.score(x_test, y_test, batch_size=128)\n",
    "    all_grids.append(g)\n",
    "    all_scores.append(score)\n",
    "    # save if best\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_grid = g\n",
    "\n",
    "print(\"OOB: %0.5f\" % best_score) \n",
    "print(\"Grid:\", best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learn_rate': 0.001, 'epochs': 15, 'dropout_rate': 0.2, 'neurons': 64}-0.4301\n",
      "{'learn_rate': 0.001, 'epochs': 15, 'dropout_rate': 0.2, 'neurons': 128}-0.4342\n",
      "{'learn_rate': 0.001, 'epochs': 15, 'dropout_rate': 0.2, 'neurons': 256}-0.4751\n",
      "{'learn_rate': 0.01, 'epochs': 15, 'dropout_rate': 0.2, 'neurons': 64}-0.407\n",
      "{'learn_rate': 0.01, 'epochs': 15, 'dropout_rate': 0.2, 'neurons': 128}-0.3706\n",
      "{'learn_rate': 0.01, 'epochs': 15, 'dropout_rate': 0.2, 'neurons': 256}-0.4504\n",
      "{'learn_rate': 0.1, 'epochs': 15, 'dropout_rate': 0.2, 'neurons': 64}-0.3382\n",
      "{'learn_rate': 0.1, 'epochs': 15, 'dropout_rate': 0.2, 'neurons': 128}-0.4082\n",
      "{'learn_rate': 0.1, 'epochs': 15, 'dropout_rate': 0.2, 'neurons': 256}-0.4174\n",
      "{'learn_rate': 0.001, 'epochs': 15, 'dropout_rate': 0.35, 'neurons': 64}-0.3845\n",
      "{'learn_rate': 0.001, 'epochs': 15, 'dropout_rate': 0.35, 'neurons': 128}-0.4144\n",
      "{'learn_rate': 0.001, 'epochs': 15, 'dropout_rate': 0.35, 'neurons': 256}-0.427\n",
      "{'learn_rate': 0.01, 'epochs': 15, 'dropout_rate': 0.35, 'neurons': 64}-0.3886\n",
      "{'learn_rate': 0.01, 'epochs': 15, 'dropout_rate': 0.35, 'neurons': 128}-0.3954\n",
      "{'learn_rate': 0.01, 'epochs': 15, 'dropout_rate': 0.35, 'neurons': 256}-0.4024\n",
      "{'learn_rate': 0.1, 'epochs': 15, 'dropout_rate': 0.35, 'neurons': 64}-0.3677\n",
      "{'learn_rate': 0.1, 'epochs': 15, 'dropout_rate': 0.35, 'neurons': 128}-0.3943\n",
      "{'learn_rate': 0.1, 'epochs': 15, 'dropout_rate': 0.35, 'neurons': 256}-0.4043\n",
      "{'learn_rate': 0.001, 'epochs': 15, 'dropout_rate': 0.5, 'neurons': 64}-0.322\n",
      "{'learn_rate': 0.001, 'epochs': 15, 'dropout_rate': 0.5, 'neurons': 128}-0.3588\n",
      "{'learn_rate': 0.001, 'epochs': 15, 'dropout_rate': 0.5, 'neurons': 256}-0.4046\n",
      "{'learn_rate': 0.01, 'epochs': 15, 'dropout_rate': 0.5, 'neurons': 64}-0.3324\n",
      "{'learn_rate': 0.01, 'epochs': 15, 'dropout_rate': 0.5, 'neurons': 128}-0.376\n",
      "{'learn_rate': 0.01, 'epochs': 15, 'dropout_rate': 0.5, 'neurons': 256}-0.4117\n",
      "{'learn_rate': 0.1, 'epochs': 15, 'dropout_rate': 0.5, 'neurons': 64}-0.2273\n",
      "{'learn_rate': 0.1, 'epochs': 15, 'dropout_rate': 0.5, 'neurons': 128}-0.293\n",
      "{'learn_rate': 0.1, 'epochs': 15, 'dropout_rate': 0.5, 'neurons': 256}-0.3453\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(all_grids)):\n",
    "    print(str(all_grids[i])+'-'+str(all_scores[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing \n",
    "I store the overal results in txt files because it require a lot of time to re-run the grid search procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_list_grid.txt', 'wb') as fp:\n",
    "    pickle.dump(all_grids, fp)\n",
    "with open('result_list_scores.txt', 'wb') as fp:\n",
    "    pickle.dump(all_scores, fp)\n",
    "with open('best_grid.txt', 'wb') as fp:\n",
    "    pickle.dump(best_grid, fp)\n",
    "with open('best_score.txt', 'wb') as fp:\n",
    "    pickle.dump(best_score, fp)\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras.models import model_from_json\n",
    "best_grid=[]\n",
    "all_grids=[]\n",
    "best_score=0\n",
    "all_scores=[]\n",
    "\n",
    "with open ('result_list_grid.txt', 'rb') as fp:\n",
    "    all_grids = pickle.load(fp)\n",
    "with open ('result_list_scores.txt', 'rb') as fp:\n",
    "    all_scores = pickle.load(fp)\n",
    "with open ('best_score.txt', 'rb') as fp:\n",
    "    best_score = pickle.load(fp)\n",
    "with open ('best_grid.txt', 'rb') as fp:\n",
    "    best_grid = pickle.load(fp)\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neurons': 256, 'dropout_rate': 0.2, 'epochs': 15, 'learn_rate': 0.001}\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               786688    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 830,282\n",
      "Trainable params: 829,386\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 17s 336us/step - loss: 1.9478 - acc: 0.3204 - val_loss: 2.0630 - val_acc: 0.2994\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.7270 - acc: 0.3812 - val_loss: 1.9922 - val_acc: 0.2617\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.6725 - acc: 0.4018 - val_loss: 1.7068 - val_acc: 0.3920\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.6247 - acc: 0.4185 - val_loss: 1.6127 - val_acc: 0.4207\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.5912 - acc: 0.4314 - val_loss: 1.7393 - val_acc: 0.3819\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.5753 - acc: 0.4379 - val_loss: 1.6240 - val_acc: 0.4118\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 1.5537 - acc: 0.4440 - val_loss: 1.5616 - val_acc: 0.4384\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.5354 - acc: 0.4519 - val_loss: 1.5117 - val_acc: 0.4556\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 15s 309us/step - loss: 1.5268 - acc: 0.4570 - val_loss: 1.4926 - val_acc: 0.4582\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.5147 - acc: 0.4576 - val_loss: 1.4517 - val_acc: 0.4756\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 14s 277us/step - loss: 1.5082 - acc: 0.4622 - val_loss: 1.4533 - val_acc: 0.4821\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 1.5067 - acc: 0.4637 - val_loss: 1.5117 - val_acc: 0.4626\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.4911 - acc: 0.4668 - val_loss: 1.5462 - val_acc: 0.4477\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.4801 - acc: 0.4737 - val_loss: 1.4687 - val_acc: 0.4736\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.4805 - acc: 0.4704 - val_loss: 1.4169 - val_acc: 0.4915\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 16s 315us/step - loss: 1.4728 - acc: 0.4749 - val_loss: 1.4299 - val_acc: 0.4911\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 1.4668 - acc: 0.4784 - val_loss: 1.4517 - val_acc: 0.4870\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 1.4548 - acc: 0.4805 - val_loss: 1.4081 - val_acc: 0.4970\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 1.4490 - acc: 0.4826 - val_loss: 1.4682 - val_acc: 0.4780\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 1.4476 - acc: 0.4864 - val_loss: 1.5182 - val_acc: 0.4509\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.4414 - acc: 0.4855 - val_loss: 1.3818 - val_acc: 0.5044\n",
      "Epoch 22/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.4398 - acc: 0.4868 - val_loss: 1.4899 - val_acc: 0.4619\n",
      "Epoch 23/100\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.4360 - acc: 0.4862 - val_loss: 1.4154 - val_acc: 0.4932\n",
      "Epoch 24/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.4287 - acc: 0.4910 - val_loss: 1.5158 - val_acc: 0.4571\n",
      "Epoch 25/100\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.4257 - acc: 0.4897 - val_loss: 1.4174 - val_acc: 0.4875\n",
      "Epoch 26/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.4184 - acc: 0.4952 - val_loss: 1.4719 - val_acc: 0.4627\n",
      "Epoch 27/100\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.4178 - acc: 0.4935 - val_loss: 1.4385 - val_acc: 0.4862\n",
      "Epoch 28/100\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.4165 - acc: 0.4966 - val_loss: 1.4497 - val_acc: 0.4799\n",
      "Epoch 29/100\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.4134 - acc: 0.4961 - val_loss: 1.4274 - val_acc: 0.4833\n",
      "Epoch 30/100\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.4065 - acc: 0.4990 - val_loss: 1.4194 - val_acc: 0.4844\n",
      "Epoch 31/100\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 1.3988 - acc: 0.5020 - val_loss: 1.4262 - val_acc: 0.4932\n",
      "Epoch 32/100\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 1.3957 - acc: 0.5044 - val_loss: 1.4095 - val_acc: 0.5001\n",
      "Epoch 33/100\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.3990 - acc: 0.5031 - val_loss: 1.4278 - val_acc: 0.4896\n",
      "Epoch 34/100\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 1.3927 - acc: 0.5033 - val_loss: 1.3842 - val_acc: 0.5079\n",
      "Epoch 35/100\n",
      "50000/50000 [==============================] - 14s 272us/step - loss: 1.3920 - acc: 0.5058 - val_loss: 1.3594 - val_acc: 0.5148\n",
      "Epoch 36/100\n",
      "50000/50000 [==============================] - 13s 270us/step - loss: 1.3906 - acc: 0.5043 - val_loss: 1.4713 - val_acc: 0.4720\n",
      "Epoch 37/100\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 1.3912 - acc: 0.5034 - val_loss: 1.3540 - val_acc: 0.5154\n",
      "Epoch 38/100\n",
      "50000/50000 [==============================] - 14s 270us/step - loss: 1.3860 - acc: 0.5086 - val_loss: 1.4207 - val_acc: 0.4892\n",
      "Epoch 39/100\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.3841 - acc: 0.5056 - val_loss: 1.4017 - val_acc: 0.4944\n",
      "Epoch 40/100\n",
      "50000/50000 [==============================] - 13s 270us/step - loss: 1.3942 - acc: 0.5063 - val_loss: 1.4012 - val_acc: 0.4958\n",
      "Epoch 41/100\n",
      "50000/50000 [==============================] - 14s 278us/step - loss: 1.3901 - acc: 0.5059 - val_loss: 1.3791 - val_acc: 0.5078\n",
      "Epoch 42/100\n",
      "50000/50000 [==============================] - 14s 281us/step - loss: 1.3837 - acc: 0.5075 - val_loss: 1.4191 - val_acc: 0.4902\n",
      "Epoch 43/100\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 1.3810 - acc: 0.5079 - val_loss: 1.3938 - val_acc: 0.4960\n",
      "Epoch 44/100\n",
      "50000/50000 [==============================] - 14s 279us/step - loss: 1.3758 - acc: 0.5100 - val_loss: 1.3899 - val_acc: 0.5050\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 13s 270us/step - loss: 1.3720 - acc: 0.5119 - val_loss: 1.4075 - val_acc: 0.5002\n",
      "Epoch 46/100\n",
      "50000/50000 [==============================] - 13s 260us/step - loss: 1.3771 - acc: 0.5131 - val_loss: 1.4044 - val_acc: 0.4967\n",
      "Epoch 47/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.3714 - acc: 0.5105 - val_loss: 1.3587 - val_acc: 0.5159\n",
      "Epoch 48/100\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.3681 - acc: 0.5153 - val_loss: 1.5270 - val_acc: 0.4580\n",
      "Epoch 49/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.3658 - acc: 0.5152 - val_loss: 1.5551 - val_acc: 0.4599\n",
      "Epoch 50/100\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3674 - acc: 0.5119 - val_loss: 1.4662 - val_acc: 0.4844\n",
      "Epoch 51/100\n",
      "50000/50000 [==============================] - 14s 277us/step - loss: 1.3651 - acc: 0.5163 - val_loss: 1.3579 - val_acc: 0.5083\n",
      "Epoch 52/100\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.3602 - acc: 0.5158 - val_loss: 1.4904 - val_acc: 0.4702\n",
      "Epoch 53/100\n",
      "50000/50000 [==============================] - 14s 275us/step - loss: 1.3648 - acc: 0.5127 - val_loss: 1.3596 - val_acc: 0.5085\n",
      "Epoch 54/100\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.3587 - acc: 0.5157 - val_loss: 1.3858 - val_acc: 0.5031\n",
      "Epoch 55/100\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.3550 - acc: 0.5187 - val_loss: 1.3682 - val_acc: 0.5059\n",
      "Epoch 56/100\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 1.3560 - acc: 0.5171 - val_loss: 1.4708 - val_acc: 0.4785\n",
      "Epoch 57/100\n",
      "50000/50000 [==============================] - 13s 251us/step - loss: 1.3536 - acc: 0.5156 - val_loss: 1.4016 - val_acc: 0.4946\n",
      "Epoch 58/100\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.3502 - acc: 0.5198 - val_loss: 1.3795 - val_acc: 0.5056\n",
      "Epoch 59/100\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 1.3482 - acc: 0.5206 - val_loss: 1.3967 - val_acc: 0.5073\n",
      "Epoch 60/100\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.3568 - acc: 0.5180 - val_loss: 1.3642 - val_acc: 0.5120\n",
      "Epoch 61/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.3606 - acc: 0.5150 - val_loss: 1.3750 - val_acc: 0.5088\n",
      "Epoch 62/100\n",
      "50000/50000 [==============================] - 14s 278us/step - loss: 1.3497 - acc: 0.5187 - val_loss: 1.3885 - val_acc: 0.5060\n",
      "Epoch 63/100\n",
      "50000/50000 [==============================] - 13s 263us/step - loss: 1.3503 - acc: 0.5213 - val_loss: 1.3783 - val_acc: 0.5095\n",
      "Epoch 64/100\n",
      "50000/50000 [==============================] - 13s 256us/step - loss: 1.3535 - acc: 0.5172 - val_loss: 1.4936 - val_acc: 0.4737\n",
      "Epoch 65/100\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.3553 - acc: 0.5192 - val_loss: 1.3646 - val_acc: 0.5127\n",
      "Epoch 66/100\n",
      "50000/50000 [==============================] - 13s 268us/step - loss: 1.3456 - acc: 0.5218 - val_loss: 1.4185 - val_acc: 0.4951\n",
      "Epoch 67/100\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 1.3685 - acc: 0.5124 - val_loss: 1.4055 - val_acc: 0.4890\n",
      "Epoch 68/100\n",
      "50000/50000 [==============================] - 14s 285us/step - loss: 1.3588 - acc: 0.5168 - val_loss: 1.4191 - val_acc: 0.4925\n",
      "Epoch 69/100\n",
      "50000/50000 [==============================] - 14s 278us/step - loss: 1.3548 - acc: 0.5157 - val_loss: 1.4070 - val_acc: 0.4926\n",
      "Epoch 70/100\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 1.3571 - acc: 0.5144 - val_loss: 1.3739 - val_acc: 0.5098\n",
      "Epoch 71/100\n",
      "50000/50000 [==============================] - 13s 266us/step - loss: 1.3458 - acc: 0.5209 - val_loss: 1.3689 - val_acc: 0.5160\n",
      "Epoch 72/100\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 1.3448 - acc: 0.5220 - val_loss: 1.3990 - val_acc: 0.5018\n",
      "Epoch 73/100\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.3485 - acc: 0.5181 - val_loss: 1.3929 - val_acc: 0.5012\n",
      "Epoch 74/100\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 1.3449 - acc: 0.5239 - val_loss: 1.3804 - val_acc: 0.5087\n",
      "Epoch 75/100\n",
      "50000/50000 [==============================] - 13s 270us/step - loss: 1.3469 - acc: 0.5197 - val_loss: 1.3843 - val_acc: 0.5062\n",
      "Epoch 76/100\n",
      "50000/50000 [==============================] - 14s 274us/step - loss: 1.3418 - acc: 0.5198 - val_loss: 1.4054 - val_acc: 0.4973\n",
      "Epoch 77/100\n",
      "50000/50000 [==============================] - 13s 252us/step - loss: 1.3453 - acc: 0.5205 - val_loss: 1.3619 - val_acc: 0.5119\n",
      "Epoch 78/100\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.3447 - acc: 0.5215 - val_loss: 1.4119 - val_acc: 0.4936\n",
      "Epoch 79/100\n",
      "50000/50000 [==============================] - 12s 241us/step - loss: 1.3429 - acc: 0.5225 - val_loss: 1.4037 - val_acc: 0.4966\n",
      "Epoch 80/100\n",
      "50000/50000 [==============================] - 13s 250us/step - loss: 1.3399 - acc: 0.5227 - val_loss: 1.3690 - val_acc: 0.5126\n",
      "Epoch 81/100\n",
      "50000/50000 [==============================] - 13s 257us/step - loss: 1.3379 - acc: 0.5238 - val_loss: 1.3977 - val_acc: 0.5001\n",
      "Epoch 82/100\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 1.3360 - acc: 0.5247 - val_loss: 1.3759 - val_acc: 0.5073\n",
      "Epoch 83/100\n",
      "50000/50000 [==============================] - 14s 288us/step - loss: 1.3388 - acc: 0.5239 - val_loss: 1.3871 - val_acc: 0.5056\n",
      "Epoch 84/100\n",
      "50000/50000 [==============================] - 13s 269us/step - loss: 1.3372 - acc: 0.5248 - val_loss: 1.4904 - val_acc: 0.4748\n",
      "Epoch 85/100\n",
      "50000/50000 [==============================] - 12s 248us/step - loss: 1.3348 - acc: 0.5245 - val_loss: 1.4107 - val_acc: 0.4891\n",
      "Epoch 86/100\n",
      "50000/50000 [==============================] - 13s 270us/step - loss: 1.3350 - acc: 0.5251 - val_loss: 1.3514 - val_acc: 0.5163\n",
      "Epoch 87/100\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 1.3335 - acc: 0.5256 - val_loss: 1.4679 - val_acc: 0.4803\n",
      "Epoch 88/100\n",
      "50000/50000 [==============================] - 14s 273us/step - loss: 1.3351 - acc: 0.5258 - val_loss: 1.3602 - val_acc: 0.5127\n",
      "Epoch 89/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.3337 - acc: 0.5248 - val_loss: 1.3760 - val_acc: 0.5064\n",
      "Epoch 90/100\n",
      "50000/50000 [==============================] - 14s 286us/step - loss: 1.3269 - acc: 0.5262 - val_loss: 1.4022 - val_acc: 0.4997\n",
      "Epoch 91/100\n",
      "50000/50000 [==============================] - 14s 271us/step - loss: 1.3252 - acc: 0.5279 - val_loss: 1.3888 - val_acc: 0.5086\n",
      "Epoch 92/100\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.3272 - acc: 0.5271 - val_loss: 1.3802 - val_acc: 0.5039\n",
      "Epoch 93/100\n",
      "50000/50000 [==============================] - 13s 259us/step - loss: 1.3297 - acc: 0.5274 - val_loss: 1.3963 - val_acc: 0.5043\n",
      "Epoch 94/100\n",
      "50000/50000 [==============================] - 13s 258us/step - loss: 1.3232 - acc: 0.5276 - val_loss: 1.4310 - val_acc: 0.4908\n",
      "Epoch 95/100\n",
      "50000/50000 [==============================] - 13s 261us/step - loss: 1.3244 - acc: 0.5258 - val_loss: 1.3973 - val_acc: 0.4973\n",
      "Epoch 96/100\n",
      "50000/50000 [==============================] - 13s 264us/step - loss: 1.3216 - acc: 0.5284 - val_loss: 1.3983 - val_acc: 0.5069\n",
      "Epoch 97/100\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 1.3149 - acc: 0.5316 - val_loss: 1.4084 - val_acc: 0.4979\n",
      "Epoch 98/100\n",
      "50000/50000 [==============================] - 13s 265us/step - loss: 1.3206 - acc: 0.5293 - val_loss: 1.4451 - val_acc: 0.4832\n",
      "Epoch 99/100\n",
      "50000/50000 [==============================] - 13s 267us/step - loss: 1.3184 - acc: 0.5298 - val_loss: 1.3713 - val_acc: 0.5130\n",
      "Epoch 100/100\n",
      "50000/50000 [==============================] - 13s 262us/step - loss: 1.3135 - acc: 0.5313 - val_loss: 1.3829 - val_acc: 0.5022\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "print(best_grid)\n",
    "model = KerasClassifier(build_fn=create_model)\n",
    "model.set_params(**best_grid)\n",
    "model_info=model.fit(x_train, y_train, \n",
    "                           batch_size=128, epochs=100, \n",
    "                           validation_data = (x_test, y_test))\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model took 1344.52 seconds to train\n",
      "[1 9 8 ... 3 6 4]\n",
      "Accuracy on test data is: 50.22\n"
     ]
    }
   ],
   "source": [
    "# plot model history\n",
    "plot_model_history(model_info)\n",
    "print (\"Model took %0.2f seconds to train\"%(end - start))\n",
    "# compute test accuracy\n",
    "print (\"Accuracy on test data is: %0.2f\"%accuracy(x_test, y_test, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuran Network Image\n",
    "Creates an image of the best neural network. Requires graphviz installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confussion Matrix,Recall and Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[566  32  24  25  33   9  28  28 198  57]\n",
      " [ 50 606  14  18  12   8  27  19  72 174]\n",
      " [112  21 224  70 217  42 180  61  45  28]\n",
      " [ 42  26  57 339  88  85 230  54  26  53]\n",
      " [ 60  13  62  44 491  19 201  64  32  14]\n",
      " [ 21  15  59 260  75 285 148  68  30  39]\n",
      " [ 11  12  25  52 117  15 708  18  22  20]\n",
      " [ 58  16  29  69 109  43  59 537  24  56]\n",
      " [101  53   7  23  18  14  17  17 691  59]\n",
      " [ 53 177   7  19   8  10  30  35  86 575]]\n",
      "F1 Score is:0.49154538104034334\n",
      "Precision Score is:0.5048436517932925\n",
      "Recall Score is:0.5022\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "result = model.predict(x_test)\n",
    "true_class = np.argmax(y_test, axis=1)\n",
    "print(confusion_matrix(true_class, result,labels=[i for i in range(10)]))\n",
    "print(\"F1 Score is:\"+str(f1_score(true_class, result, average=\"macro\")))\n",
    "print(\"Precision Score is:\"+str(precision_score(true_class, result, average=\"macro\")))\n",
    "print(\"Recall Score is:\"+str(recall_score(true_class, result, average=\"macro\")))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
